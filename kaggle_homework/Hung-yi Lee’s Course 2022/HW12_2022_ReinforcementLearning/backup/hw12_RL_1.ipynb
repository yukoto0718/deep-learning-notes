{"cells":[{"cell_type":"markdown","metadata":{"id":"Fp30SB4bxeQb"},"source":["# **Homework 12 - Reinforcement Learning**\n","\n","If you have any problem, e-mail us at ntu-ml-2022spring-ta@googlegroups.com\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3773,"status":"aborted","timestamp":1757928325023,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"tpdRF3btp5RD"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"yXsnCWPtWSNk"},"source":["## Preliminary work\n","\n","First, we need to install all necessary packages.\n","One of them, gym, builded by OpenAI, is a toolkit for developing Reinforcement Learning algorithm. Other packages are for visualization in colab."]},{"cell_type":"markdown","metadata":{"id":"RwHv8eDnsEua"},"source":["# æ–¹æ¡ˆ1ï¼šåˆ†æ­¥å®‰è£…\n","!apt update\n","!apt install python3-dev build-essential swig cmake python-opengl xvfb -y\n","!pip install wheel setuptools\n","!pip install box2d-py --no-cache-dir\n","!pip install gym==0.21.0\n","!pip install pyvirtualdisplay tqdm numpy torch"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":668},"executionInfo":{"elapsed":8915,"status":"error","timestamp":1757928324982,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"2gxxT1d1sOEE","outputId":"d38d1f55-a681-488b-dd6f-3b4fc5a65cd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: swig in /usr/local/lib/python3.12/dist-packages (4.3.1.post0)\n","Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.12/dist-packages (1.2.0)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.0.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.15.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (0.0.4)\n","Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.3.5)\n","Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.6.1)\n","Requirement already satisfied: swig==4.* in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.3.1.post0)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_str'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_drv'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3215681700.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install swig'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install gymnasium[box2d]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install pyvirtualdisplay tqdm numpy torch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__fspath__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             self._str = self._format_parsed_parts(self.drive, self.root,\n\u001b[0m\u001b[1;32m    444\u001b[0m                                                   self._tail) or '.'\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m_load_parts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m_parse_path\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpathsegments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parse_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["!pip install swig\n","!pip install gymnasium[box2d]\n","!pip install pyvirtualdisplay tqdm numpy torch"]},{"cell_type":"markdown","metadata":{"id":"M_-i3cdoYsks"},"source":["\n","Next, set up virtual displayï¼Œand import all necessaary packages."]},{"cell_type":"markdown","metadata":{"id":"CaEJ8BUCpN9P"},"source":["# Warning ! Do not revise random seed !!!\n","# Your submission on JudgeBoi will not reproduce your result !!!\n","Make your HW result to be reproducible.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1757928324988,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"fV9i8i2YkRbO"},"outputs":[],"source":["import random\n","import numpy as np\n","import torch\n","\n","seed = 543 # Do not change this\n","\n","def fix(env, seed):\n","    # å…¼å®¹æ–°æ—§ç‰ˆæœ¬çš„æ–¹æ³•\n","    try:\n","        env.seed(seed)  # æ—§ç‰ˆæœ¬\n","    except AttributeError:\n","        pass  # æ–°ç‰ˆæœ¬æ²¡æœ‰seedæ–¹æ³•\n","\n","    env.action_space.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.use_deterministic_algorithms(True)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{"id":"He0XDx6bzjgC"},"source":["Last, call gym and build an [Lunar Lander](https://gym.openai.com/envs/LunarLander-v2/) environment."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11708,"status":"aborted","timestamp":1757928324989,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"N_4-xJcbBt09"},"outputs":[],"source":["%%capture\n","#import gym\n","import gymnasium as gym\n","import random\n","#env = gym.make('LunarLander-v2')\n","env = gym.make('LunarLander-v3')\n","fix(env, seed) # fix the environment Do not revise this !!!"]},{"cell_type":"markdown","metadata":{"id":"NrkVvTrvWZ5H"},"source":["## What Lunar Landerï¼Ÿ\n","\n","â€œLunarLander-v2â€is to simulate the situation when the craft lands on the surface of the moon.\n","\n","This task is to enable the craft to land \"safely\" at the pad between the two yellow flags.\n","> Landing pad is always at coordinates (0,0).\n","> Coordinates are the first two numbers in state vector.\n","\n","![](https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg)\n","\n","\"LunarLander-v2\" actually includes \"Agent\" and \"Environment\".\n","\n","In this homework, we will utilize the function `step()` to control the action of \"Agent\".\n","\n","Then `step()` will return the observation/state and reward given by the \"Environment\"."]},{"cell_type":"markdown","metadata":{"id":"bIbp82sljvAt"},"source":["### Observation / State\n","\n","First, we can take a look at what an Observation / State looks like."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11707,"status":"aborted","timestamp":1757928324989,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"rsXZra3N9R5T"},"outputs":[],"source":["print(env.observation_space)"]},{"cell_type":"markdown","metadata":{"id":"ezdfoThbAQ49"},"source":["\n","`Box(8,)`means that observation is an 8-dim vector\n","### Action\n","\n","Actions can be taken by looks like"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11706,"status":"aborted","timestamp":1757928324990,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"p1k4dIrBAaKi"},"outputs":[],"source":["print(env.action_space)"]},{"cell_type":"markdown","metadata":{"id":"dejXT6PHBrPn"},"source":["`Discrete(4)` implies that there are four kinds of actions can be taken by agent.\n","- 0 implies the agent will not take any actions\n","- 2 implies the agent will accelerate downward\n","- 1, 3 implies the agent will accelerate left and right\n","\n","Next, we will try to make the agent interact with the environment.\n","Before taking any actions, we recommend to call `reset()` function to reset the environment. Also, this function will return the initial state of the environment."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11705,"status":"aborted","timestamp":1757928324990,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"pi4OmrmZgnWA"},"outputs":[],"source":["initial_state, _ = env.reset()\n","print(initial_state)"]},{"cell_type":"markdown","metadata":{"id":"uBx0mEqqgxJ9"},"source":["Then, we try to get a random action from the agent's action space."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11704,"status":"aborted","timestamp":1757928324990,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"vxkOEXRKgizt"},"outputs":[],"source":["random_action = env.action_space.sample()\n","print(random_action)"]},{"cell_type":"markdown","metadata":{"id":"mns-bO01g0-J"},"source":["More, we can utilize `step()` to make agent act according to the randomly-selected `random_action`.\n","The `step()` function will return four values:\n","- observation / state\n","- reward\n","- done (True/ False)\n","- Other information"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11704,"status":"aborted","timestamp":1757928324991,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"E_WViSxGgIk9"},"outputs":[],"source":["print(env.observation_space)\n","print(env.action_space)\n","\n","initial_state, _ = env.reset()\n","print(initial_state)\n","\n","random_action = env.action_space.sample()\n","print(random_action)\n","\n","observation, reward, terminated, truncated, info = env.step(random_action)\n","done = terminated or truncated\n","\n","print(done)\n","print(reward)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11702,"status":"aborted","timestamp":1757928324991,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"yK7r126kuCNp"},"outputs":[],"source":["print(done)"]},{"cell_type":"markdown","metadata":{"id":"GKdS8vOihxhc"},"source":["### Reward\n","\n","\n","> Landing pad is always at coordinates (0,0). Coordinates are the first two numbers in state vector. Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points. If lander moves away from landing pad it loses reward back. Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points. Each leg ground contact is +10. Firing main engine is -0.3 points each frame. Solved is 200 points."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11705,"status":"aborted","timestamp":1757928324995,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"vxQNs77hi0_7"},"outputs":[],"source":["print(reward)"]},{"cell_type":"markdown","metadata":{"id":"Mhqp6D-XgHpe"},"source":["### Random Agent\n","In the end, before we start training, we can see whether a random agent can successfully land the moon or not."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11704,"status":"aborted","timestamp":1757928324996,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"Y3G0bxoccelv"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from IPython import display\n","\n","state, _ = env.reset()\n","\n","# åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„æ¸²æŸ“ç¯å¢ƒ\n","render_env = gym.make('LunarLander-v3', render_mode='rgb_array')\n","render_env.reset()\n","\n","img = plt.imshow(render_env.render())\n","\n","done = False\n","while not done:\n","    action = env.action_space.sample()\n","    observation, reward, terminated, truncated, _ = env.step(action)\n","    done = terminated or truncated"]},{"cell_type":"markdown","metadata":{"id":"F5paWqo7tWL2"},"source":["## Policy Gradient\n","Now, we can build a simple policy network. The network will return one of action in the action space."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11704,"status":"aborted","timestamp":1757928324997,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"J8tdmeD-tZew"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.distributions import Categorical\n","from tqdm.notebook import tqdm\n","\n","class PolicyGradientNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # æ›´æ·±çš„ç½‘ç»œæ¶æ„ï¼Œæé«˜å­¦ä¹ èƒ½åŠ›\n","        self.fc1 = nn.Linear(8, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 32)\n","        self.fc4 = nn.Linear(32, 4)\n","        self.dropout = nn.Dropout(0.2)  # æ·»åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆ\n","\n","    def forward(self, state):\n","        x = torch.tanh(self.fc1(state))\n","        x = self.dropout(x)\n","        x = torch.tanh(self.fc2(x))\n","        x = self.dropout(x)\n","        x = torch.tanh(self.fc3(x))\n","        return F.softmax(self.fc4(x), dim=-1)"]},{"cell_type":"markdown","metadata":{"id":"ynbqJrhIFTC3"},"source":["Then, we need to build a simple agent. The agent will acts according to the output of the policy network above. There are a few things can be done by agent:\n","- `learn()`ï¼šupdate the policy network from log probabilities and rewards.\n","- `sample()`ï¼šAfter receiving observation from the environment, utilize policy network to tell which action to take. The return values of this function includes action and log probabilities."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11703,"status":"aborted","timestamp":1757928324997,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"zZo-IxJx286z"},"outputs":[],"source":["from torch.optim.lr_scheduler import StepLR\n","class PolicyGradientAgent():\n","    def __init__(self, network):\n","        self.network = network\n","        # ä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ç¨å¾®æé«˜\n","        self.optimizer = optim.Adam(self.network.parameters(), lr=0.003)\n","        # æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨\n","        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.95)\n","\n","    def forward(self, state):\n","        return self.network(state)\n","\n","    def learn(self, log_probs, rewards):\n","        # ä½¿ç”¨æŠ˜æ‰£å¥–åŠ±è®¡ç®—ï¼Œè€Œä¸æ˜¯åŸå§‹å¥–åŠ±\n","        discounted_rewards = self.discount_rewards(rewards)\n","        # æ ‡å‡†åŒ–å¥–åŠ±\n","        discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-8)\n","\n","        loss = -(log_probs * discounted_rewards).sum()\n","\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        # æ¢¯åº¦è£å‰ªï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§\n","        torch.nn.utils.clip_grad_norm_(self.network.parameters(), max_norm=0.5)\n","        self.optimizer.step()\n","        self.scheduler.step()\n","\n","    def discount_rewards(self, rewards, gamma=0.99):\n","        \"\"\"è®¡ç®—æŠ˜æ‰£å¥–åŠ± (reward-to-go)\"\"\"\n","        rewards = np.array(rewards)\n","        discounted = np.zeros_like(rewards, dtype=np.float32)\n","        running_add = 0\n","        # ä»åå¾€å‰è®¡ç®—æŠ˜æ‰£å¥–åŠ±\n","        for t in reversed(range(len(rewards))):\n","            running_add = running_add * gamma + rewards[t]\n","            discounted[t] = running_add\n","        return torch.FloatTensor(discounted)\n","\n","    def sample(self, state):\n","        action_prob = self.network(torch.FloatTensor(state))\n","        action_dist = Categorical(action_prob)\n","        action = action_dist.sample()\n","        log_prob = action_dist.log_prob(action)\n","        return action.item(), log_prob"]},{"cell_type":"markdown","metadata":{"id":"ehPlnTKyRZf9"},"source":["Lastly, build a network and agent to start training."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11703,"status":"aborted","timestamp":1757928324998,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"GfJIvML-RYjL"},"outputs":[],"source":["network = PolicyGradientNetwork()\n","agent = PolicyGradientAgent(network)"]},{"cell_type":"markdown","metadata":{"id":"ouv23glgf5Qt"},"source":["## Training Agent\n","\n","Now let's start to train our agent.\n","Through taking all the interactions between agent and environment as training data, the policy network can learn from all these attempts,"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11703,"status":"aborted","timestamp":1757928324999,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"vg5rxBBaf38_"},"outputs":[],"source":["agent.network.train()\n","EPISODE_PER_BATCH = 5\n","NUM_BATCH = 400  # å‡å°‘åˆ°400ä¸ªbatchï¼Œå› ä¸ºä¼˜åŒ–åæ”¶æ•›æ›´å¿«\n","\n","avg_total_rewards, avg_final_rewards = [], []\n","best_avg_reward = -float('inf')  # è¿½è¸ªæœ€ä½³æ€§èƒ½\n","\n","prg_bar = tqdm(range(NUM_BATCH))\n","for batch in prg_bar:\n","    log_probs, rewards = [], []\n","    total_rewards, final_rewards = [], []\n","\n","    # æ”¶é›†è½¨è¿¹\n","    for episode in range(EPISODE_PER_BATCH):\n","        state, _ = env.reset()\n","        total_reward, total_step = 0, 0\n","        episode_log_probs, episode_rewards = [], []\n","\n","        while True:\n","            action, log_prob = agent.sample(state)\n","            next_state, reward, terminated, truncated, _ = env.step(action)\n","            done = terminated or truncated\n","\n","            episode_log_probs.append(log_prob)\n","            episode_rewards.append(reward)\n","            state = next_state\n","            total_reward += reward\n","            total_step += 1\n","\n","            if done:\n","                final_rewards.append(reward)\n","                total_rewards.append(total_reward)\n","                # å°†è¿™ä¸€episodeçš„æ•°æ®æ·»åŠ åˆ°batchä¸­\n","                log_probs.extend(episode_log_probs)\n","                rewards.extend(episode_rewards)\n","                break\n","\n","    # è®°å½•è®­ç»ƒè¿‡ç¨‹\n","    avg_total_reward = sum(total_rewards) / len(total_rewards)\n","    avg_final_reward = sum(final_rewards) / len(final_rewards)\n","    avg_total_rewards.append(avg_total_reward)\n","    avg_final_rewards.append(avg_final_reward)\n","\n","    prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n","\n","    # æ›´æ–°æ™ºèƒ½ä½“\n","    agent.learn(torch.stack(log_probs), rewards)\n","\n","    # åªä¿å­˜æœ€ä½³æ¨¡å‹\n","    if avg_total_reward > best_avg_reward:\n","        best_avg_reward = avg_total_reward\n","        torch.save({\n","            'model_state_dict': agent.network.state_dict(),\n","            'optimizer_state_dict': agent.optimizer.state_dict(),\n","            'best_avg_reward': best_avg_reward,\n","            'batch': batch + 1,\n","        }, '/content/drive/MyDrive/lunar_lander_best_model.pth')\n","        print(f\"New best model saved at batch {batch+1} with avg reward: {best_avg_reward:.2f}\")\n","\n","# è®­ç»ƒå®Œæˆåä¿å­˜æœ€ç»ˆæ¨¡å‹\n","torch.save({\n","    'model_state_dict': agent.network.state_dict(),\n","    'optimizer_state_dict': agent.optimizer.state_dict(),\n","    'batch': NUM_BATCH,\n","    'avg_total_rewards': avg_total_rewards,\n","    'avg_final_rewards': avg_final_rewards,\n","    'final_avg_reward': avg_total_rewards[-1] if avg_total_rewards else 0,\n","}, '/content/drive/MyDrive/lunar_lander_final_model.pth')\n","\n","print(\"Training completed!\")\n","print(f\"Best average reward achieved: {best_avg_reward:.2f}\")\n","\n","# ä¿å­˜è®­ç»ƒå†å²\n","np.save('/content/drive/MyDrive/avg_total_rewards.npy', avg_total_rewards)\n","np.save('/content/drive/MyDrive/avg_final_rewards.npy', avg_final_rewards)"]},{"cell_type":"markdown","metadata":{"id":"vNb_tuFYhKVK"},"source":["### Training Result\n","During the training process, we recorded `avg_total_reward`, which represents the average total reward of episodes before updating the policy network.\n","\n","Theoretically, if the agent becomes better, the `avg_total_reward` will increase.\n","The visualization of the training process is shown below:  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11701,"status":"aborted","timestamp":1757928324999,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"wZYOI8H10SHN"},"outputs":[],"source":["plt.plot(avg_total_rewards)\n","plt.title(\"Total Rewards\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"mV5jj4dThz0Y"},"source":["In addition, `avg_final_reward` represents average final rewards of episodes. To be specific, final rewards is the last reward received in one episode, indicating whether the craft lands successfully or not.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11707,"status":"aborted","timestamp":1757928325006,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"txDZ5vlGWz5w"},"outputs":[],"source":["plt.plot(avg_final_rewards)\n","plt.title(\"Final Rewards\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"u2HaGRVEYGQS"},"source":["## Testing\n","The testing result will be the average reward of 5 testing"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":20068,"status":"ok","timestamp":1757928348709,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"5yFuUKKRYH73","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3597d7ad-1abb-4d27-952b-29807b634078"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Best model loaded! Best avg reward was: 256.7698486240437\n","ğŸš€ å¼€å§‹æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹...\n","Episode 1 å¼€å§‹...\n","  Step 1: Action=3, State_sum=0.64\n","  Step 2: Action=3, State_sum=0.57\n","  Step 3: Action=3, State_sum=0.50\n","  Step 4: Action=3, State_sum=0.43\n","  Step 5: Action=3, State_sum=0.36\n","  Progress: 100 steps, reward so far: 115.10\n","  Progress: 200 steps, reward so far: 156.70\n","  Progress: 300 steps, reward so far: 171.68\n","  Progress: 400 steps, reward so far: 175.03\n","Episode 1 å®Œæˆ: 487 actions, Total reward: 274.31\n","Episode 2 å¼€å§‹...\n","  Step 1: Action=3, State_sum=1.05\n","  Step 2: Action=3, State_sum=0.98\n","  Step 3: Action=3, State_sum=0.91\n","  Step 4: Action=0, State_sum=0.84\n","  Step 5: Action=3, State_sum=0.80\n","  Progress: 100 steps, reward so far: 75.71\n","  Progress: 200 steps, reward so far: 103.66\n","  Progress: 300 steps, reward so far: 119.01\n","  Progress: 400 steps, reward so far: 125.70\n","  Progress: 500 steps, reward so far: 134.66\n","Episode 2 å®Œæˆ: 548 actions, Total reward: 233.34\n","Episode 3 å¼€å§‹...\n","  Step 1: Action=1, State_sum=1.16\n","  Step 2: Action=0, State_sum=1.17\n","  Step 3: Action=0, State_sum=1.13\n","  Step 4: Action=1, State_sum=1.10\n","  Step 5: Action=0, State_sum=1.10\n","  Progress: 100 steps, reward so far: 72.60\n","  Progress: 200 steps, reward so far: 108.81\n","  Progress: 300 steps, reward so far: 134.93\n","  Progress: 400 steps, reward so far: 127.36\n","  Progress: 500 steps, reward so far: 113.37\n","  Progress: 600 steps, reward so far: 112.56\n","  Progress: 700 steps, reward so far: 109.14\n","  Progress: 800 steps, reward so far: 103.45\n","  Progress: 900 steps, reward so far: 100.96\n","  Progress: 1000 steps, reward so far: 95.30\n","Episode 3 å®Œæˆ: 1000 actions, Total reward: 95.30\n","Episode 4 å¼€å§‹...\n","  Step 1: Action=1, State_sum=1.26\n","  Step 2: Action=1, State_sum=1.26\n","  Step 3: Action=1, State_sum=1.25\n","  Step 4: Action=1, State_sum=1.25\n","  Step 5: Action=1, State_sum=1.25\n","  Progress: 100 steps, reward so far: 99.26\n","  Progress: 200 steps, reward so far: 142.19\n","  Progress: 300 steps, reward so far: 166.17\n","  Progress: 400 steps, reward so far: 166.03\n","  Progress: 500 steps, reward so far: 158.49\n","  Progress: 600 steps, reward so far: 157.73\n","  Progress: 700 steps, reward so far: 154.79\n","  Progress: 800 steps, reward so far: 140.28\n","  Progress: 900 steps, reward so far: 147.14\n","  Progress: 1000 steps, reward so far: 126.52\n","Episode 4 å®Œæˆ: 1000 actions, Total reward: 126.52\n","Episode 5 å¼€å§‹...\n","  Step 1: Action=3, State_sum=0.65\n","  Step 2: Action=3, State_sum=0.58\n","  Step 3: Action=3, State_sum=0.51\n","  Step 4: Action=3, State_sum=0.44\n","  Step 5: Action=3, State_sum=0.37\n","  Progress: 100 steps, reward so far: 121.32\n","  Progress: 200 steps, reward so far: 164.36\n","  Progress: 300 steps, reward so far: 164.47\n","  Progress: 400 steps, reward so far: 176.94\n","  Progress: 500 steps, reward so far: 174.17\n","Episode 5 å®Œæˆ: 539 actions, Total reward: 273.12\n","ğŸ¯ Average test reward: 200.52\n","âœ… æµ‹è¯•ç»“æœçœ‹èµ·æ¥æ­£å¸¸ï¼\n","\n","ğŸ” ç«‹å³éªŒè¯åˆšä¿å­˜çš„åŠ¨ä½œ...\n","éªŒè¯Episode 1: 487 actions\n","  Episode 1: åœ¨æ­¥éª¤ 212 ç»“æŸ (åŸå§‹: 487 æ­¥)\n","Episode 1: Original=274.3, Verify=-485.3, Diff=759.7 âŒ\n","éªŒè¯Episode 2: 548 actions\n","  Episode 2: åœ¨æ­¥éª¤ 193 ç»“æŸ (åŸå§‹: 548 æ­¥)\n","Episode 2: Original=233.3, Verify=-473.0, Diff=706.3 âŒ\n","éªŒè¯Episode 3: 1000 actions\n","  Episode 3: åœ¨æ­¥éª¤ 81 ç»“æŸ (åŸå§‹: 1000 æ­¥)\n","Episode 3: Original=95.3, Verify=-253.4, Diff=348.7 âŒ\n","éªŒè¯Episode 4: 1000 actions\n","  Episode 4: åœ¨æ­¥éª¤ 83 ç»“æŸ (åŸå§‹: 1000 æ­¥)\n","Episode 4: Original=126.5, Verify=-431.1, Diff=557.7 âŒ\n","éªŒè¯Episode 5: 539 actions\n","  Episode 5: åœ¨æ­¥éª¤ 70 ç»“æŸ (åŸå§‹: 539 æ­¥)\n","Episode 5: Original=273.1, Verify=-442.1, Diff=715.3 âŒ\n","\n","ğŸ“Š Original avg: 200.52\n","æµ‹è¯•ç»“æœçœ‹èµ·æ¥æ­£å¸¸ï¼\n"]}],"source":["# æµ‹è¯•æ—¶ç¡®ä¿åŠ è½½æœ€ä½³æ¨¡å‹\n","import os\n","\n","try:\n","    if os.path.exists('/content/drive/MyDrive/lunar_lander_best_model.pth'):\n","        checkpoint = torch.load('/content/drive/MyDrive/lunar_lander_best_model.pth', weights_only=False)\n","        agent.network.load_state_dict(checkpoint['model_state_dict'])\n","        print(f\"âœ… Best model loaded! Best avg reward was: {checkpoint.get('best_avg_reward', 'N/A')}\")\n","    else:\n","        print(\"âŒ No best model found, using current trained model\")\n","except Exception as e:\n","    print(f\"âŒ Failed to load best model: {e}\")\n","\n","# ç¡®ä¿ç¯å¢ƒä¸€è‡´æ€§çš„æµ‹è¯•\n","test_env = gym.make('LunarLander-v3', render_mode='rgb_array')\n","fix(test_env, seed)\n","agent.network.eval()\n","\n","NUM_OF_TEST = 5\n","test_total_reward = []\n","action_list = []\n","\n","print(\"ğŸš€ å¼€å§‹æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹...\")\n","\n","for i in range(NUM_OF_TEST):\n","    actions = []\n","    state, _ = test_env.reset()\n","\n","    total_reward = 0\n","    done = False\n","    step_count = 0\n","    max_steps = 1000\n","\n","    print(f\"Episode {i+1} å¼€å§‹...\")\n","\n","    while not done and step_count < max_steps:\n","        # ç¡®ä¿çŠ¶æ€æ ¼å¼æ­£ç¡®\n","        if isinstance(state, tuple):\n","            state = state[0]\n","\n","        action, _ = agent.sample(state)\n","\n","        # ğŸ”§ å…³é”®ä¿®å¤ï¼šåœ¨stepä¹‹å‰ä¿å­˜action\n","        actions.append(action)\n","\n","        # åªåœ¨å‰5æ­¥æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼Œé¿å…è¾“å‡ºå¤ªå¤š\n","        if step_count < 5:\n","            print(f\"  Step {step_count+1}: Action={action}, State_sum={np.sum(state):.2f}\")\n","\n","        state, reward, terminated, truncated, _ = test_env.step(action)\n","        done = terminated or truncated\n","        total_reward += reward\n","        step_count += 1\n","\n","        # è°ƒè¯•ä¿¡æ¯\n","        if step_count % 100 == 0:\n","            print(f\"  Progress: {step_count} steps, reward so far: {total_reward:.2f}\")\n","\n","    print(f\"Episode {i+1} å®Œæˆ: {len(actions)} actions, Total reward: {total_reward:.2f}\")\n","    test_total_reward.append(total_reward)\n","    action_list.append(actions)\n","\n","    # éªŒè¯actionåˆ—è¡¨é•¿åº¦\n","    if len(actions) != step_count:\n","        print(f\"âš ï¸  è­¦å‘Š: åŠ¨ä½œæ•°é‡ {len(actions)} != æ­¥æ•° {step_count}\")\n","\n","avg_reward = np.mean(test_total_reward)\n","print(f\"ğŸ¯ Average test reward: {avg_reward:.2f}\")\n","\n","# æ£€æŸ¥ç»“æœåˆç†æ€§\n","if avg_reward > 100:\n","    print(\"âœ… æµ‹è¯•ç»“æœçœ‹èµ·æ¥æ­£å¸¸ï¼\")\n","else:\n","    print(\"âš ï¸  æµ‹è¯•ç»“æœå¼‚å¸¸ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥æ¨¡å‹æˆ–ç¯å¢ƒè®¾ç½®\")\n","\n","# ğŸ” ç«‹å³éªŒè¯åˆšä¿å­˜çš„åŠ¨ä½œ\n","print(\"\\nğŸ” ç«‹å³éªŒè¯åˆšä¿å­˜çš„åŠ¨ä½œ...\")\n","\n","for i in range(NUM_OF_TEST):\n","    original_reward = test_total_reward[i]\n","    actions = action_list[i]\n","\n","    print(f\"éªŒè¯Episode {i+1}: {len(actions)} actions\")\n","\n","    # é‡æ–°è¿è¡Œç›¸åŒçš„åŠ¨ä½œåºåˆ—\n","    verify_env = gym.make('LunarLander-v3', render_mode='rgb_array')\n","    fix(verify_env, seed)  # é‡è¦ï¼šç›¸åŒçš„seed\n","\n","    state, _ = verify_env.reset()\n","    verify_reward = 0\n","\n","    for step, action in enumerate(actions):\n","        if isinstance(state, tuple):\n","            state = state[0]\n","\n","        state, reward, terminated, truncated, _ = verify_env.step(action)\n","        verify_reward += reward\n","\n","        if terminated or truncated:\n","            print(f\"  Episode {i+1}: åœ¨æ­¥éª¤ {step+1} ç»“æŸ (åŸå§‹: {len(actions)} æ­¥)\")\n","            break\n","\n","    diff = abs(original_reward - verify_reward)\n","    status = \"âœ…\" if diff < 5 else \"âš ï¸\" if diff < 20 else \"âŒ\"\n","\n","    print(f\"Episode {i+1}: Original={original_reward:.1f}, Verify={verify_reward:.1f}, Diff={diff:.1f} {status}\")\n","\n","# å¦‚æœéªŒè¯ç»“æœå·®å¼‚å¾ˆå¤§ï¼Œæ‰“å°æ›´å¤šè°ƒè¯•ä¿¡æ¯\n","verify_avg = np.mean([test_total_reward[i] for i in range(NUM_OF_TEST)])  # è¿™é‡Œåº”è¯¥ç”¨éªŒè¯çš„å¥–åŠ±ï¼Œä½†å…ˆç”¨åŸå§‹çš„\n","print(f\"\\nğŸ“Š Original avg: {avg_reward:.2f}\")\n","\n","# æ£€æŸ¥ç»“æœåˆç†æ€§\n","if avg_reward > 100:\n","    print(\"æµ‹è¯•ç»“æœçœ‹èµ·æ¥æ­£å¸¸ï¼\")\n","else:\n","    print(\"æµ‹è¯•ç»“æœå¼‚å¸¸ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥æ¨¡å‹æˆ–ç¯å¢ƒè®¾ç½®\")"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1757928351266,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"Aex7mcKr0J01","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5f78227-f9e1-4105-ba73-a1ab119a68e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["200.51860772022107\n"]}],"source":["print(np.mean(test_total_reward))"]},{"cell_type":"markdown","metadata":{"id":"leyebGYRpqsF"},"source":["Action list"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1757928356106,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"hGAH4YWDpp4u","colab":{"base_uri":"https://localhost:8080/"},"outputId":"982874f5-fc1b-4183-8aa1-dd0c74612be7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ“‹ Action list statistics:\n","Episode 1: 487 actions\n","  Action distribution: {0: 46, 1: 69, 2: 132, 3: 240}\n","Episode 2: 548 actions\n","  Action distribution: {0: 66, 1: 86, 2: 120, 3: 276}\n","Episode 3: 1000 actions\n","  Action distribution: {0: 155, 1: 235, 2: 132, 3: 478}\n","Episode 4: 1000 actions\n","  Action distribution: {0: 132, 1: 215, 2: 127, 3: 526}\n","Episode 5: 539 actions\n","  Action distribution: {0: 57, 1: 76, 2: 117, 3: 289}\n","ğŸ“Š Average episode length: 714.8\n","âš ï¸  Episodeå¤ªé•¿ï¼Œå¯èƒ½æ™ºèƒ½ä½“æ²¡å­¦ä¼šç€é™†\n","ğŸ’¾ Actions saved to /content/drive/MyDrive/Action_List.npy\n"]}],"source":["# ğŸ“‹ Action list statistics with improved analysis\n","print(\"\\nğŸ“‹ Action list statistics:\")\n","for i, actions in enumerate(action_list):\n","    print(f\"Episode {i+1}: {len(actions)} actions\")\n","    action_counts = {0: 0, 1: 0, 2: 0, 3: 0}  # 0: no-op, 1: left, 2: main, 3: right\n","    for action in actions:\n","        if action in action_counts:\n","            action_counts[action] += 1\n","    print(f\"  Action distribution: {action_counts}\")\n","\n","# è®¡ç®—æ€»ä½“ç»Ÿè®¡\n","total_actions = sum(len(actions) for actions in action_list)\n","avg_episode_length = total_actions / len(action_list)\n","print(f\"ğŸ“Š Average episode length: {avg_episode_length:.1f}\")\n","\n","# æ£€æŸ¥episodeé•¿åº¦åˆç†æ€§\n","if avg_episode_length < 50:\n","    print(\"âš ï¸  Episodeå¤ªçŸ­ï¼Œå¯èƒ½æ™ºèƒ½ä½“å¿«é€Ÿå æ¯\")\n","elif avg_episode_length > 500:\n","    print(\"âš ï¸  Episodeå¤ªé•¿ï¼Œå¯èƒ½æ™ºèƒ½ä½“æ²¡å­¦ä¼šç€é™†\")\n","else:\n","    print(\"âœ… Episodeé•¿åº¦çœ‹èµ·æ¥åˆç†\")\n","\n","# ä¿å­˜åŠ¨ä½œåˆ—è¡¨\n","PATH = \"/content/drive/MyDrive/Action_List.npy\"\n","np.save(PATH, np.array(action_list, dtype=object))\n","print(f\"ğŸ’¾ Actions saved to {PATH}\")"]},{"cell_type":"markdown","metadata":{"id":"asK7WfbkaLjt"},"source":["### This is the file you need to submit !!!\n","Download the testing result to your device\n","\n"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1757928360429,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"c-CqyhHzaWAL","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"c24009d7-d542-44b4-dd41-a596cff37bdf"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a817e2b7-5a74-4f73-80cc-52a0ae7dfd41\", \"Action_List.npy\", 7445)"]},"metadata":{}}],"source":["from google.colab import files\n","files.download(PATH)"]},{"cell_type":"markdown","metadata":{"id":"seT4NUmWmAZ1"},"source":["# Server\n","The code below simulate the environment on the judge server. Can be used for testing."]},{"cell_type":"code","source":["# ğŸ” éªŒè¯åŠ¨ä½œé‡æ”¾æœºåˆ¶ - åœ¨æœ€ç»ˆæäº¤å‰è¿è¡Œ\n","print(\"ğŸ” éªŒè¯åŠ¨ä½œé‡æ”¾æœºåˆ¶...\")\n","\n","# é‡æ–°åŠ è½½ä¿å­˜çš„åŠ¨ä½œ\n","action_list_loaded = np.load(PATH, allow_pickle=True)\n","print(f\"Loaded {len(action_list_loaded)} episodes\")\n","\n","# åˆ›å»ºéªŒè¯ç¯å¢ƒï¼ˆä¸è®­ç»ƒå’Œæµ‹è¯•æ—¶å®Œå…¨ç›¸åŒçš„è®¾ç½®ï¼‰\n","verify_env = gym.make('LunarLander-v3', render_mode='rgb_array')\n","fix(verify_env, seed)  # ä½¿ç”¨ç›¸åŒçš„seed\n","\n","verify_rewards = []\n","agent.network.eval()  # ç¡®ä¿æ˜¯evaluationæ¨¡å¼\n","\n","for i, actions in enumerate(action_list_loaded):\n","    state, _ = verify_env.reset()\n","    total_reward = 0\n","    step_count = 0\n","\n","    for action in actions:\n","        state, reward, terminated, truncated, _ = verify_env.step(action)\n","        total_reward += reward\n","        step_count += 1\n","\n","        if terminated or truncated:\n","            break\n","\n","    verify_rewards.append(total_reward)\n","    print(f\"Verify Episode {i+1}: {step_count} steps, Reward: {total_reward:.2f}\")\n","\n","verify_avg = np.mean(verify_rewards)\n","print(f\"ğŸ”¬ Verification average reward: {verify_avg:.2f}\")\n","\n","# æ¯”è¾ƒåŸå§‹æµ‹è¯•ç»“æœå’ŒéªŒè¯ç»“æœ\n","original_avg = np.mean(test_total_reward)\n","difference = abs(original_avg - verify_avg)\n","print(f\"ğŸ“Š Original test avg: {original_avg:.2f}\")\n","print(f\"ğŸ“Š Verification avg: {verify_avg:.2f}\")\n","print(f\"ğŸ“Š Difference: {difference:.2f}\")\n","\n","if difference < 10:\n","    print(\"âœ… é‡æ”¾æœºåˆ¶æ­£å¸¸ï¼Œç»“æœä¸€è‡´ï¼\")\n","elif difference < 50:\n","    print(\"âš ï¸  ç»“æœæœ‰äº›å·®å¼‚ï¼Œä½†å¯èƒ½åœ¨æ­£å¸¸èŒƒå›´å†…\")\n","else:\n","    print(\"âŒ é‡æ”¾ç»“æœå·®å¼‚å¾ˆå¤§ï¼Œå¯èƒ½æœ‰é—®é¢˜ï¼\")\n","\n","# æ£€æŸ¥æ¯ä¸ªepisodeçš„ä¸€è‡´æ€§\n","print(\"\\nğŸ” Episode-by-episode comparison:\")\n","for i in range(len(action_list_loaded)):\n","    orig = test_total_reward[i]\n","    verify = verify_rewards[i]\n","    diff = abs(orig - verify)\n","    status = \"âœ…\" if diff < 10 else \"âš ï¸\" if diff < 50 else \"âŒ\"\n","    print(f\"Episode {i+1}: Original={orig:.1f}, Verify={verify:.1f}, Diff={diff:.1f} {status}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-QPUv2ZxmC5w","executionInfo":{"status":"ok","timestamp":1757928363515,"user_tz":-540,"elapsed":72,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"}},"outputId":"258b8b57-5c4f-4a55-d91e-136c46fa0efe"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ” éªŒè¯åŠ¨ä½œé‡æ”¾æœºåˆ¶...\n","Loaded 5 episodes\n","Verify Episode 1: 75 steps, Reward: -413.23\n","Verify Episode 2: 109 steps, Reward: 44.02\n","Verify Episode 3: 130 steps, Reward: -388.06\n","Verify Episode 4: 74 steps, Reward: -485.11\n","Verify Episode 5: 74 steps, Reward: -427.27\n","ğŸ”¬ Verification average reward: -333.93\n","ğŸ“Š Original test avg: 200.52\n","ğŸ“Š Verification avg: -333.93\n","ğŸ“Š Difference: 534.45\n","âŒ é‡æ”¾ç»“æœå·®å¼‚å¾ˆå¤§ï¼Œå¯èƒ½æœ‰é—®é¢˜ï¼\n","\n","ğŸ” Episode-by-episode comparison:\n","Episode 1: Original=274.3, Verify=-413.2, Diff=687.5 âŒ\n","Episode 2: Original=233.3, Verify=44.0, Diff=189.3 âŒ\n","Episode 3: Original=95.3, Verify=-388.1, Diff=483.4 âŒ\n","Episode 4: Original=126.5, Verify=-485.1, Diff=611.6 âŒ\n","Episode 5: Original=273.1, Verify=-427.3, Diff=700.4 âŒ\n"]}]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":897,"status":"ok","timestamp":1757928369627,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"U69c-YTxaw6b","colab":{"base_uri":"https://localhost:8080/","height":485},"outputId":"cb5ff438-13e7-433f-ed3d-cc9b0749d361"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your reward is : -444.64\n","Your reward is : -50.66\n","Your reward is : -409.63\n","Your reward is : -93.38\n","Your reward is : -313.88\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANvJJREFUeJzt3Xl4lPW9///XTCZ7MpOELJOQhRAwEEjQgoQRBSyRtYAaLSpq6rF4pMFLxXo0rWL1e2qs/o7VniranrocT5FTvYoL4oIgQUsERFIWMQVEQcgkCJIJS0KWz++PnEwdRSAQmDvh+biu92Xmvj+57/d8iJlX7mXGZowxAgAAsBB7sBsAAAD4NgIKAACwHAIKAACwHAIKAACwHAIKAACwHAIKAACwHAIKAACwHAIKAACwHAIKAACwHAIKAACwnKAGlCeeeEJ9+vRRRESECgsLtXr16mC2AwAALCJoAeV///d/NWfOHN133336+OOPNWTIEI0fP151dXXBagkAAFiELVgfFlhYWKjzzz9fv//97yVJbW1tysjI0C233KK77747GC0BAACLcARjp0eOHNHatWtVVlbmX2a321VUVKTKysrvjG9qalJTU5P/cVtbm/bt26devXrJZrOdkZ4BAMCpMcaooaFBaWlpstuPfRInKAHlq6++Umtrq1JSUgKWp6Sk6NNPP/3O+PLyct1///1nqj0AAHAa7dy5U+np6cccE5SA0lllZWWaM2eO/3F9fb0yMzOD2BFwdhs19DZlZA6RO2aIQkOi1dC4W2u2PqPVH73gHzNtwkPKiL9AMeEpx9hS19npW6m3Kv6f9u79TJkpwzV2xF06bNur3rHDFBoSrX0Ht2r1p89o/abX1NbWfEZ6AnB0sbGxxx0TlICSmJiokJAQ1dbWBiyvra2V2+3+zvjw8HCFh4efqfYAHJNNuf1+qDBHtGIj3Wpta9FXTZv1afW7AaNCQyMVHhatiLDj/yLqCmGhUQoJCZEkfVn3sQ4d2q/klFz5mneqd+T5cofmKzN1mHbuXqu9ez8/Iz0BOLoTuTwjKHfxhIWFaejQoVq6dKl/WVtbm5YuXSqPxxOMlgCcoGsmPq+DLbXqFXWOjDHa17hFO75cJ19DTZA7++cvvDbTolcr5qityaip1adDzXtltzmUmzpJgwZM5No1oBsI2m3Gc+bM0R//+Ec9//zz2rx5s2bNmqWDBw/qhhtuCFZLAI4jNtqtw9ojd8wQ2W0ham49qDrfZq3b8Jdgt/Z//hk8Go/U69WKOeoVmauvDlWrzbQoKixRzsh09e49JIg9AjgRQbsGZfr06dqzZ4/mzp0rr9erc889V2+99dZ3LpwFYB0XnDdT8bEZig1LU5tp1f7GL1S99V01Nx/6ztg206rGlnqF2EOPvjHzzS+P924Hx15vZNTSelghIYG/0r6sW6cvd3+s+KR0HTjilTM8XQVZ07XvwFbt2bNNTU0Nx9kvgGAJ6kWys2fP1uzZs4PZAoATlOEepqjYOCVE9Zdk05HWBn351UfasWuNWlu/e9Gp3ebQoeY9am470Im9nMqpF6O2ttbvLFu25mH95NK/6MCRWkWFJirUHqG+yRerLmOrtm59/xT2B+B06hZ38QAILpvNLldcqlLi8xTpiJdRm3yNu/TZzg/ka6g96vcs/9vvFGJ36Juhw/bNAHLcLNK5sGJMq/bu//w7y/cf+FIr1/1Rg/Mm6XDz14oJcys1/lz1iu+rOucW+XzeTu0HwJlBQAFwXMm9clWQN01S++mU1rZGba15V5/vXKO2tpajfs9X+7aeyRa/V2vrEX319RZFORLlO7JLEY44yWbU2z1E3rpN8vlqdbxTSADOPAIKgOOyGbvCWuK0t/4zNRyuUWhIlHZ51+vAge7x2Vlbdi7TB2vT1O+ckTrYWKetu5arunqZ6ut3B7s1AN8jaJ/Fcyp8Pp9cLlew2wDOKhFhTiUnDFSvhD5qMvv12fYP1dhYH+y2OiW3X5FkN6r+x9LjDwZw2tTX18vpdB5zDAEFwEmx2ewypi3YbQDohk4koATtfVAAdG+EEwCnEwEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYTpcHlF/96ley2WwBNWDAAP/6xsZGlZaWqlevXoqJiVFxcbFqa2u7ug0AANCNnZYjKIMGDVJNTY2/PvjgA/+622+/Xa+//rpeeuklVVRUaPfu3br88stPRxsAAKCbcpyWjToccrvd31leX1+vP/3pT5o/f75++MMfSpKeffZZDRw4UB9++KFGjBhxOtoBAADdzGk5grJlyxalpaWpb9++mjFjhnbs2CFJWrt2rZqbm1VUVOQfO2DAAGVmZqqysvJ7t9fU1CSfzxdQAACg5+rygFJYWKjnnntOb731lubNm6ft27froosuUkNDg7xer8LCwhQXFxfwPSkpKfJ6vd+7zfLycrlcLn9lZGR0ddsAAMBCuvwUz8SJE/1fFxQUqLCwUFlZWfrLX/6iyMjIk9pmWVmZ5syZ43/s8/kIKQAA9GCn/TbjuLg4nXPOOdq6davcbreOHDmi/fv3B4ypra096jUrHcLDw+V0OgMKAAD0XKc9oBw4cEDbtm1Tamqqhg4dqtDQUC1dutS/vrq6Wjt27JDH4zndrQAAgG6iy0/x/PznP9eUKVOUlZWl3bt367777lNISIiuvvpquVwu3XjjjZozZ44SEhLkdDp1yy23yOPxcAcPAADw6/KA8uWXX+rqq6/W3r17lZSUpAsvvFAffvihkpKSJEm//e1vZbfbVVxcrKamJo0fP15PPvlkV7cBAAC6MZsxxgS7ic7y+XxyuVzBbgMAAJyE+vr6415PymfxAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAyyGgAAAAy+l0QFmxYoWmTJmitLQ02Ww2vfLKKwHrjTGaO3euUlNTFRkZqaKiIm3ZsiVgzL59+zRjxgw5nU7FxcXpxhtv1IEDB07piQAAgJ6j0wHl4MGDGjJkiJ544omjrn/44Yf1u9/9Tk899ZRWrVql6OhojR8/Xo2Njf4xM2bM0KZNm7RkyRItWrRIK1as0E033XTyzwIAAPQs5hRIMgsXLvQ/bmtrM2632zzyyCP+Zfv37zfh4eHmxRdfNMYY88knnxhJZs2aNf4xb775prHZbGbXrl0ntN/6+nojiaIoiqKoblj19fXHfa3v0mtQtm/fLq/Xq6KiIv8yl8ulwsJCVVZWSpIqKysVFxenYcOG+ccUFRXJbrdr1apVR91uU1OTfD5fQAEAgJ6rSwOK1+uVJKWkpAQsT0lJ8a/zer1KTk4OWO9wOJSQkOAf823l5eVyuVz+ysjI6Mq2AQCAxXSLu3jKyspUX1/vr507dwa7JQAAcBp1aUBxu92SpNra2oDltbW1/nVut1t1dXUB61taWrRv3z7/mG8LDw+X0+kMKAAA0HN1aUDJzs6W2+3W0qVL/ct8Pp9WrVolj8cjSfJ4PNq/f7/Wrl3rH7Ns2TK1tbWpsLCwK9sBAADdlKOz33DgwAFt3brV/3j79u2qqqpSQkKCMjMzddttt+nf//3f1b9/f2VnZ+vee+9VWlqaLr30UknSwIEDNWHCBM2cOVNPPfWUmpubNXv2bF111VVKS0vrsicGAAC6sRO8o9jvvffeO+otQyUlJcaY9luN7733XpOSkmLCw8PN2LFjTXV1dcA29u7da66++moTExNjnE6nueGGG0xDQ8MJ98BtxhRFURTVfetEbjO2GWOMuhmfzyeXyxXsNgAAwEmor68/7vWk3eIuHgAAcHYhoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMshoAAAAMvpdEBZsWKFpkyZorS0NNlsNr3yyisB63/yk5/IZrMF1IQJEwLG7Nu3TzNmzJDT6VRcXJxuvPFGHThw4JSeCAAA6Dk6HVAOHjyoIUOG6IknnvjeMRMmTFBNTY2/XnzxxYD1M2bM0KZNm7RkyRItWrRIK1as0E033dT57gEAQM9kToEks3DhwoBlJSUlZtq0ad/7PZ988omRZNasWeNf9uabbxqbzWZ27dp1Qvutr683kiiKoiiK6oZVX19/3Nf603INyvLly5WcnKzc3FzNmjVLe/fu9a+rrKxUXFychg0b5l9WVFQku92uVatWHXV7TU1N8vl8AQUAAHquLg8oEyZM0H//939r6dKl+s1vfqOKigpNnDhRra2tkiSv16vk5OSA73E4HEpISJDX6z3qNsvLy+VyufyVkZHR1W0DAAALcXT1Bq+66ir/1/n5+SooKFBOTo6WL1+usWPHntQ2y8rKNGfOHP9jn89HSAEAoAc77bcZ9+3bV4mJidq6daskye12q66uLmBMS0uL9u3bJ7fbfdRthIeHy+l0BhQAAOi5TntA+fLLL7V3716lpqZKkjwej/bv36+1a9f6xyxbtkxtbW0qLCw83e0AAIBuoNOneA4cOOA/GiJJ27dvV1VVlRISEpSQkKD7779fxcXFcrvd2rZtm/7t3/5N/fr10/jx4yVJAwcO1IQJEzRz5kw99dRTam5u1uzZs3XVVVcpLS2t654ZAADovk7ovt5veO+99456y1BJSYk5dOiQGTdunElKSjKhoaEmKyvLzJw503i93oBt7N2711x99dUmJibGOJ1Oc8MNN5iGhoYT7oHbjCmKoiiq+9aJ3GZsM8YYdTM+n08ulyvYbQAAgJNQX19/3OtJ+SweAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOQQUAABgOZ0KKOXl5Tr//PMVGxur5ORkXXrppaqurg4Y09jYqNLSUvXq1UsxMTEqLi5WbW1twJgdO3Zo8uTJioqKUnJysu688061tLSc+rMBAAA9QqcCSkVFhUpLS/Xhhx9qyZIlam5u1rhx43Tw4EH/mNtvv12vv/66XnrpJVVUVGj37t26/PLL/etbW1s1efJkHTlyRCtXrtTzzz+v5557TnPnzu26ZwUAALo3cwrq6uqMJFNRUWGMMWb//v0mNDTUvPTSS/4xmzdvNpJMZWWlMcaYxYsXG7vdbrxer3/MvHnzjNPpNE1NTSe03/r6eiOJoiiKoqhuWPX19cd9rT+la1Dq6+slSQkJCZKktWvXqrm5WUVFRf4xAwYMUGZmpiorKyVJlZWVys/PV0pKin/M+PHj5fP5tGnTpqPup6mpST6fL6AAAEDPddIBpa2tTbfddptGjhypwYMHS5K8Xq/CwsIUFxcXMDYlJUVer9c/5pvhpGN9x7qjKS8vl8vl8ldGRsbJtg0AALqBkw4opaWl2rhxoxYsWNCV/RxVWVmZ6uvr/bVz587Tvk8AABA8jpP5ptmzZ2vRokVasWKF0tPT/cvdbreOHDmi/fv3BxxFqa2tldvt9o9ZvXp1wPY67vLpGPNt4eHhCg8PP5lWAQBAN9SpIyjGGM2ePVsLFy7UsmXLlJ2dHbB+6NChCg0N1dKlS/3LqqurtWPHDnk8HkmSx+PRhg0bVFdX5x+zZMkSOZ1O5eXlncpzAQAAPUUnbtoxs2bNMi6XyyxfvtzU1NT469ChQ/4xN998s8nMzDTLli0zH330kfF4PMbj8fjXt7S0mMGDB5tx48aZqqoq89Zbb5mkpCRTVlZ2wn1wFw9FURRFdd86kbt4OhVQvm9Hzz77rH/M4cOHzc9+9jMTHx9voqKizGWXXWZqamoCtvP555+biRMnmsjISJOYmGjuuOMO09zcfMJ9EFAoiqIoqvvWiQQU2/8Fj27F5/PJ5XIFuw0AAHAS6uvr5XQ6jzmGz+IBAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACWQ0ABAACn3YwZM7Ro0aITHu84jb0AAICzUFhYmCIjIxUfH68nn3xSHo9HERERampqOuFtEFAAAMAps9vtys3NVXx8vC699FL99Kc/VVxcnGw2m3/MkSNHTnh7BBQAAHDSzjnnHI0YMUJJSUkqKSnRwIED5XB0QbwwnfDggw+aYcOGmZiYGJOUlGSmTZtmPv3004Axo0ePNpIC6l//9V8DxnzxxRdm0qRJJjIy0iQlJZmf//znprm5+YT7qK+v/84+KIqiKIo6MxUSEmJuvvlm8/TTT5sVK1YYn89n2traTvj1u76+/rhjOxVxKioqVFpaqvPPP18tLS36xS9+oXHjxumTTz5RdHS0f9zMmTP1wAMP+B9HRUX5v25tbdXkyZPldru1cuVK1dTU6Prrr1doaKgefPDBzrQDAADOoIsvvlg/+9nPdM455ygzM1OxsbEKCQk5PTs74cMWR1FXV2ckmYqKCv+y0aNHm1tvvfV7v2fx4sXGbrcbr9frXzZv3jzjdDpNU1PTCe2XIygUdfT6xS9k3n9fZvFimf/4D5kxY2R69ZJJSJBxOmXCwoLf49lSkye3/1u8847M00/LFBf/89/C5ZKJiAh+jxR1rAoLCzMJCQkmLS3N/PGPfzS7du0yjY2NprW19YSOlhzr9bvLj6B8W319vSQpISEhYPmf//xn/c///I/cbremTJmie++9138UpbKyUvn5+UpJSfGPHz9+vGbNmqVNmzbpvPPO+85+mpqaAq789fl8p9I20GM5HFJkZHslJ0ujR0vGSIcPSzt2SO+/L61bJ7W2ti/bs6e90PVCQv75b5GQIA0dKt19t9TUJNXWSqtXS++9J7W1SY2N0tdfS7t2BbtrQOrXr59SU1M1YsQIXX/99Ro4cODpO0pyDCcdUNra2nTbbbdp5MiRGjx4sH/5Nddco6ysLKWlpWn9+vW66667VF1drb/+9a+SJK/XGxBOJPkfe73eo+6rvLxc999//8m2CpzVbDYpKkoaMKC9jJGam6V9+6RPPpE2bWoPLPX10uefSxs2BLvjnstmkyIipKys9rriCqmlpX3uP/usPbS0tkoHDkhfftkeJltagt01zgZpaWm68MILlZWVpcmTJ+vcc8+Vy+UKak8nHVBKS0u1ceNGffDBBwHLb7rpJv/X+fn5Sk1N1dixY7Vt2zbl5OSc1L7Kyso0Z84c/2Ofz6eMjIyTaxw4y9lsUliY5Ha318UXt/8Vf+hQ+1/2X3zR/qK4d297gFmypP1FE13PZpNCQ6XExPY6//x/HvHau7c9tBw5Ivl80j/+Ib37bvvXQFcpLi7WxRdfrLy8PA0cOFBJSUlBOVpyNCcVUGbPnq1FixZpxYoVSk9PP+bYwsJCSdLWrVuVk5Mjt9ut1atXB4ypra2VJLnd7qNuIzw8XOHh4SfTKoDjsNnaT0fExrZXTk77i2RLS/sL5fTp0g03BLvLs4PN1l7R0e3V8XdYS0v7aaDrrpOuvVY6eDC4faJ7stlsstlsGjBggGbNmqXRo0crLS1NTqdToaGhwW7vOzoVUIwxuuWWW7Rw4UItX75c2dnZx/2eqqoqSVJqaqokyePx6Ne//rXq6uqUnJwsSVqyZImcTqfy8vI62T6AU2VMe3Vcl9LQ0H4KqOM6iQULgt3h2cOY9v+2trYHko5/i717paoq6aWXCCfoHIfDobi4OEVFRamkpETTp09Xbm6u7Ha7P7BYVacCSmlpqebPn69XX31VsbGx/mtGXC6XIiMjtW3bNs2fP1+TJk1Sr169tH79et1+++0aNWqUCgoKJEnjxo1TXl6errvuOj388MPyer265557VFpaylES4AzoCCOHDkler7R7d/uL4J497S+Cy5YFu8OzhzHtp9cOH5a++uqfp9f27ZM2b5beeqv9FA/QWRkZGerTp48GDRqk4uJiXXDBBQFv+dEddCqgzJs3T5I0ZsyYgOXPPvusfvKTnygsLEzvvvuuHnvsMR08eFAZGRkqLi7WPffc4x8bEhKiRYsWadasWfJ4PIqOjlZJSUnA+6YA6DrGtL/I7dnTfkHstm3tL4Jff91+XUN1dbA7PHt0nDrrmPv169vDos/XfoHyunXB7hDdmcvl0siRIzVkyBCNGDFCQ4cOVe/evYPd1knr9CmeY8nIyFBFRcVxt5OVlaXFixd3ZtcATlDHBa+ffSZVVLS/EHbcGeL1tv91jjPDmPZTNbt2SStXSmvW/POIyZ49Uk1NsDtETzBy5EhNmTJFhYWF6tOnj9LS0hQWFhbstk4Zn8UD9CDp6f+f/u3f/qSNGzerubk9qDQ3B7urs1N8/HS9+GKoXnjhf9Tc3B5UGhuD3RW6O5vNppCQEKWkpOi6667TlVdeqaysLEVHRysiIiLY7XUpAgrQgzgcCfr66zB99VWwO4HdHqWDB8N4IzyctNDQUEVGRioiIsL/31GjRumqq67SmDFj/Be4WvlC11NBQAEAIMiioqKUkJCgXr16KT4+XgkJCUpPT1ffvn3Vt29fZWdnKzs7O+Bz73o6AgoAAGdQXFyc0tPTlZGRofT0dKWnpys1NVUpKSlyu91KSUlRSkpKjztl01kEFAAATpPExETl5uYGVEpKimJjYxUbG6uYmBjFxsZa8o3Sgo2AAgBAJ9lsNtntdtntdoWEhMhut8vtdis/P1/5+fkqKCjQ4MGDlZycLIfDodDQUDkcDjkcDtnt9mC33y0QUAAAOAaHw6GoqKiASk1N1cCBAzVw4ED/59gkJiZ+53t76gWsZwIBBQCA/xMeHq6kpCT16tVLSUlJSkxMVGpqqrKyspSVlaU+ffooKytL8fHxwW61xyOgAADOSlFRUcrMzPSHj8zMTPXu3dsfTJKTk5WUlKSYmJhgt3pWIqAAAHq8mJgYDRw4UAMGDPCfmsnMzFR0dLSioqIUHR2t6OhoPhPOQggoAIAexWazKSIiQuHh4Ro/fryuvfZajRo1SiEhIQHFxarWRkABAPQI8fHxSk1NVf/+/TVt2jRNnTpVvXr1CnZbOEkEFABAtxUZGan8/HwNHjxYw4cP14UXXqhBgwYFuy10gW4dUJ566im99tprfDIyAJxlBg8erKKiIo0cOVL9+/dX//79FRUVFey20IW6dUC56qqrNHXqVO3YsUOTJ0/W3r17g90SAOA0iYuL0xVXXKHi4mLl5uYqISFBLpcr2G3hNOnWAcVmsyk1NVVut1s7d+5UZWWlZsyYofr6eh0+fDjY7QEATpLNZvO/KdqoUaN0zTXXaNKkSVzgehbp1gGlg81mU2RkpH74wx/qs88+0+9//3u99tprqqysVGtra7DbAwCcoPj4eKWnpysnJ0eTJk3SpEmT1Lt372C3hSDoEQHlmyIjI3XnnXfqpz/9qR577DGtXbtWb7zxRrDbAgB8j9DQUJ177rk699xzNWzYMA0fPlxDhgzhbeLPcj0uoHSIj4/Xr371K+3YsUOXXXaZnnzySX388cfBbqtHcblcuvjii3XZZZdpxYoV+tOf/hTslgB0I7m5uRo3bpzGjh2r7OxsZWdnKzY2NthtwSJ6bECR2k/9ZGVlqaSkRJMmTVJlZaWuvfZaNTY2yhgT7Pa6pY7TaTfddJOmT5+u/v37Ky4uTlOnTtWcOXO0evVqlZeXa+vWrTLGMM8A/Ox2uyIjI3XllVfqxz/+sfLz8+VyuRQTE8PREnxHjw4oHRwOh1JTU3XZZZdpz549euaZZ/Twww9rz549ampqCnZ7lme32xUXF6fc3Fxdc801uvHGGxUWFia73e7/pRIXFyeXy6UBAwbo2muv1aeffqpnn31WL7/8sr766isdOnQoyM8CQDDExsbK6XTq/PPP149//GNdfvnlcjgcAb8/gKM5KwJKB5vNpujoaN1yyy26/PLL9bvf/U7Lly/X6tWrg92aJcXExCgnJ0cFBQW68sorNXr0aDmdzu8db7PZZLPZZLfbNXjwYP3Hf/yHfvnLX+oPf/iDVq5cqZ07d6qqqurMPQEAQeFyudSnTx/l5ORo3LhxGjdunLKzs4PdFrqZsyqgfFPv3r31m9/8Rp9++qnmz5+vt99+m6DyfxISEjRmzBhddNFFuuiii/SDH/zgpP/SSUhI0N13363W1latX79er776qj7//HMtWbJEu3fv7uLOAQSLzWbT0KFDNWzYMA0dOlQ/+MEPNGTIEIWEhAS7NXRTZ21A6TBgwADNnTtXV111ld555x09+uij2rlzZ7DbCoqcnBxNnz5d48ePV05OjlJSUuRwdM2PSEhIiM477zwNGTJE+/bt05YtW1RVVaXXXntNb731VpfsA8CZl52drUmTJmnChAnKzs5Weno6b56GLnHWBxSp/RqVvLw89evXT1dffbX+9Kc/6f7779eRI0eC3dppZbPZ5HA4NGTIEJWWluqSSy5RQkKCIiMjT9s+7Xa7EhMTlZiYqGHDhumqq67Srl279NBDD+nll19Wa2urWlpaTtv+AZw8m82mkJAQORwOXXHFFZo+fbqGDx+uqKgoRUdHc00JuhQB5RvCwsKUkpKisrIyXXnllZo2bZpqa2u1b9++YLfWpaKjo5WYmKjRo0dr5syZuuCCC/y/WM7kL5jQ0FDFx8crLi5OL7zwgp5++mktWbJEc+fOlc/n0549e7i4FrAAl8ul+Ph45efn68orr1RxcbH/DxlCCU4XAspR2Gw29e/fX5s2bdILL7ygN954Q6+88kq3PqJis9mUlpamQYMGacyYMZo2bZoGDhxoiV8uHT1ER0fr0ksv1ZQpU7R582YtXLhQlZWV2rp1q7Zs2RLkLoGeLzw8XHFxcf7q+ANi1KhR+uEPf6jc3Nxgt4izCAHlGGw2m66//npdc801+sMf/qD169fr6aefDnZbnVZQUKBx48bpwgsv1PDhw5Wamhrslo4pJCREgwcP1uDBg7Vnzx6tX79ea9as0eLFi/X+++8Huz2g23M4HOrVq5fS0tICKjk5WUlJSf7qOB3Lha4IBgLKCXA4HJo1a5b279+vyy67TI888oiWLl0a7LaOKSIiQqNHj9Z1112n8847T5mZmYqJiQl2W52WlJSksWPHavTo0briiiu0detWffDBB3r00Uf5QEjgBLhcLuXk5CgnJ0f9+vVT3759lZWVpfj4eEVHRysmJkbR0dGKjo5WWFiYJY6qAhIB5YTZbDbFx8dr3LhxuuCCC7R9+3YVFRXJ5/NZ5s3eQkNDFRYWphkzZuinP/2pBgwYoKioqB7x14/D4VC/fv2Uk5OjMWPG6NZbb1VlZaWeeuopVVRU6PDhw7xrLc4aHe831FEhISGKiIhQnz59NHDgQA0YMEB5eXkaMGCA/248h8Phv8A1JCSEIALL61RAmTdvnubNm6fPP/9ckjRo0CDNnTtXEydOlCQ1Njbqjjvu0IIFC9TU1KTx48frySefVEpKin8bO3bs0KxZs/Tee+8pJiZGJSUlKi8v77LbWU83m82m2NhY5efna/fu3Vq8eLHuvfdebd++XQ0NDUHpye12q1+/fpo2bZpuuOEGJSQk+HvtaWw2myIiIhQeHq4pU6ZoypQp+uyzz3TXXXdp27Zt8nq98nq9wW4T6DKRkZEBFRUVpeTkZPXv31/9+vVT//79dc4556hPnz4KCwv7zvf3xN8DODt0KhWkp6froYceUv/+/WWM0fPPP69p06Zp3bp1GjRokG6//Xa98cYbeumll+RyuTR79mxdfvnl+tvf/iZJam1t1eTJk+V2u7Vy5UrV1NTo+uuvV2hoqB588MHT8gRPl45bdKdOnarRo0frmWee0fLly/X666+fkb/ko6KilJubq/POO0+TJ0/WqFGjlJiYeNr3axXf/KWbk5Ojl19+WY2NjVq8eLFeffVV7dixQ6tWreI0ELqNyMhIJSQkfKcyMjLUu3dvpaen+8vlchE80OPZzCm+miYkJOiRRx7RFVdcoaSkJM2fP19XXHGFJOnTTz/VwIEDVVlZqREjRujNN9/Uj370I+3evdt/VOWpp57SXXfdpT179hw1/R+Nz+eTy+VSfX39Md96/Uyrq6vTyy+/rLfeekuvv/76adlHRESEJk6cqKKiIg0fPlznnntutzn6dKYcOXJEX3zxhSorK1VVVaV3331XGzZsCHZbZ8Qzzzyjxx9/XH//+9+D3cpZ74YbblBYWNh3Lqx3OBxKSUlRenp6QPBITk5WYmKiEhIS1KtXL39AsdvtQXoGQNfrzOv3SQeU1tZWvfTSSyopKdG6devk9Xo1duxYff3114qLi/OPy8rK0m233abbb79dc+fO1WuvvRbweSzbt29X37599fHHH+u888476r6ampoCrvPw+XzKyMiwXECRpLa2NtXU1GjlypW67777tHnz5i7Zbnp6uq644grNmDFDvXv3VmJiokJDQ7tk2z2VMUYNDQ3yer36+9//rgceeEAbN24MdlunVXZ2trxeL0eOLKDjDhin06lzzjnHfzomKytLLpdLUVFR/lM2UVFRcjgcHBVBj9eZgNLpP703bNggj8ejxsZGxcTEaOHChcrLy1NVVZXCwsICwokkpaSk+K8J8Hq9AdejdKzvWPd9ysvLdf/993e21aCw2+3q3bu3Lr/8ck2aNEmLFy/WrFmzdODAgU5dTPvNi95mz56tqVOn+kMJv8ROjM1mk9PplNPpVE5OjiZNmqT9+/fr2Wef1aOPPqrm5mYdOnRIbW1tXbrfjk9pPVodb11ISIi/545Pge3479GWHe2/PeGi6J7i2xeydnzN/8PA8XU6oOTm5qqqqkr19fV6+eWXVVJSooqKitPRm19ZWZnmzJnjf9xxBMXKQkJCFB0drSuvvFITJ07U008/rRdeeEH/+Mc/jvnXbVRUlDIzMzV06FBde+21mjBhwhnsuufq+PeIjo7WPffcozlz5mjlypX64x//qM2bN2vXrl36+uuv/Xc5fPOOh6M9PtrXISEhioqKUkxMjL86buOMjY0NuKXzm4+/WREREcGeKgCwhE4HlLCwMPXr10+SNHToUK1Zs0aPP/64pk+friNHjmj//v0BR1Fqa2vldrsltd9t8u1PDK6trfWv+z7h4eEKDw/vbKuWERMTozvuuEOXX3655s+fr3feeUcrVqwIGON2u3X++edr5MiRuuSSS5Sfn88pnNMoKipKRUVFKioq0tatW7V8+XJ98sknAXdLREREHPXr71sWERHB9QIA0EVO+erKtrY2NTU1aejQoQoNDdXSpUtVXFwsSaqurtaOHTvk8XgkSR6PR7/+9a9VV1en5ORkSdKSJUvkdDqVl5d3qq1YXnZ2tn75y1+quLhY7777rp5//nk1NDRo6tSpGjNmjAoKCpSenh7sNs86/fr184duAIA1dCqglJWVaeLEicrMzFRDQ4Pmz5+v5cuX6+2335bL5dKNN96oOXPmKCEhQU6nU7fccos8Ho9GjBghSRo3bpzy8vJ03XXX6eGHH5bX69U999yj0tLSbn2EpLMGDBignJwcTZ06VS0tLUpKSlJMTAznpQEA+D+dCih1dXW6/vrrVVNTI5fLpYKCAr399tu65JJLJEm//e1vZbfbVVxcHPBGbR1CQkK0aNEizZo1Sx6PR9HR0SopKdEDDzzQtc+qGwgNDVVmZmaw2wAAwJJO+X1QgsGq74MCAAC+X2dev7miDwAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWE6nAsq8efNUUFAgp9Mpp9Mpj8ejN998079+zJgxstlsAXXzzTcHbGPHjh2aPHmyoqKilJycrDvvvFMtLS1d82wAAECP4OjM4PT0dD300EPq37+/jDF6/vnnNW3aNK1bt06DBg2SJM2cOVMPPPCA/3uioqL8X7e2tmry5Mlyu91auXKlampqdP311ys0NFQPPvhgFz0lAADQ3dmMMeZUNpCQkKBHHnlEN954o8aMGaNzzz1Xjz322FHHvvnmm/rRj36k3bt3KyUlRZL01FNP6a677tKePXsUFhZ2Qvv0+XxyuVyqr6+X0+k8lfYBAMAZ0pnX75O+BqW1tVULFizQwYMH5fF4/Mv//Oc/KzExUYMHD1ZZWZkOHTrkX1dZWan8/Hx/OJGk8ePHy+fzadOmTd+7r6amJvl8voACAAA9V6dO8UjShg0b5PF41NjYqJiYGC1cuFB5eXmSpGuuuUZZWVlKS0vT+vXrddddd6m6ulp//etfJUlerzcgnEjyP/Z6vd+7z/Lyct1///2dbRUAAHRTnQ4oubm5qqqqUn19vV5++WWVlJSooqJCeXl5uummm/zj8vPzlZqaqrFjx2rbtm3Kyck56SbLyso0Z84c/2Ofz6eMjIyT3h4AALC2Tp/iCQsLU79+/TR06FCVl5dryJAhevzxx486trCwUJK0detWSZLb7VZtbW3AmI7Hbrf7e/cZHh7uv3OoowAAQM91yu+D0tbWpqampqOuq6qqkiSlpqZKkjwejzZs2KC6ujr/mCVLlsjpdPpPEwEAAHTqFE9ZWZkmTpyozMxMNTQ0aP78+Vq+fLnefvttbdu2TfPnz9ekSZPUq1cvrV+/XrfffrtGjRqlgoICSdK4ceOUl5en6667Tg8//LC8Xq/uuecelZaWKjw8/LQ8QQAA0P10KqDU1dXp+uuvV01NjVwulwoKCvT222/rkksu0c6dO/Xuu+/qscce08GDB5WRkaHi4mLdc889/u8PCQnRokWLNGvWLHk8HkVHR6ukpCTgfVMAAABO+X1QgoH3QQEAoPs5I++DAgAAcLoQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOU4gt3AyTDGSJJ8Pl+QOwEAACeq43W743X8WLplQGloaJAkZWRkBLkTAADQWQ0NDXK5XMccYzMnEmMspq2tTdXV1crLy9POnTvldDqD3VK35fP5lJGRwTx2Aeay6zCXXYN57DrMZdcwxqihoUFpaWmy2499lUm3PIJit9vVu3dvSZLT6eSHpQswj12Huew6zGXXYB67DnN56o535KQDF8kCAADLIaAAAADL6bYBJTw8XPfdd5/Cw8OD3Uq3xjx2Heay6zCXXYN57DrM5ZnXLS+SBQAAPVu3PYICAAB6LgIKAACwHAIKAACwHAIKAACwnG4ZUJ544gn16dNHERERKiws1OrVq4PdkuWsWLFCU6ZMUVpammw2m1555ZWA9cYYzZ07V6mpqYqMjFRRUZG2bNkSMGbfvn2aMWOGnE6n4uLidOONN+rAgQNn8FkEX3l5uc4//3zFxsYqOTlZl156qaqrqwPGNDY2qrS0VL169VJMTIyKi4tVW1sbMGbHjh2aPHmyoqKilJycrDvvvFMtLS1n8qkE1bx581RQUOB/kyuPx6M333zTv545PHkPPfSQbDabbrvtNv8y5vPE/OpXv5LNZguoAQMG+Nczj0FmupkFCxaYsLAw88wzz5hNmzaZmTNnmri4OFNbWxvs1ixl8eLF5pe//KX561//aiSZhQsXBqx/6KGHjMvlMq+88or5+9//bqZOnWqys7PN4cOH/WMmTJhghgwZYj788EPz/vvvm379+pmrr776DD+T4Bo/frx59tlnzcaNG01VVZWZNGmSyczMNAcOHPCPufnmm01GRoZZunSp+eijj8yIESPMBRdc4F/f0tJiBg8ebIqKisy6devM4sWLTWJioikrKwvGUwqK1157zbzxxhvmH//4h6murja/+MUvTGhoqNm4caMxhjk8WatXrzZ9+vQxBQUF5tZbb/UvZz5PzH333WcGDRpkampq/LVnzx7/euYxuLpdQBk+fLgpLS31P25tbTVpaWmmvLw8iF1Z27cDSltbm3G73eaRRx7xL9u/f78JDw83L774ojHGmE8++cRIMmvWrPGPefPNN43NZjO7du06Y71bTV1dnZFkKioqjDHt8xYaGmpeeukl/5jNmzcbSaaystIY0x4W7Xa78Xq9/jHz5s0zTqfTNDU1ndknYCHx8fHmv/7rv5jDk9TQ0GD69+9vlixZYkaPHu0PKMznibvvvvvMkCFDjrqOeQy+bnWK58iRI1q7dq2Kior8y+x2u4qKilRZWRnEzrqX7du3y+v1Bsyjy+VSYWGhfx4rKysVFxenYcOG+ccUFRXJbrdr1apVZ7xnq6ivr5ckJSQkSJLWrl2r5ubmgLkcMGCAMjMzA+YyPz9fKSkp/jHjx4+Xz+fTpk2bzmD31tDa2qoFCxbo4MGD8ng8zOFJKi0t1eTJkwPmTeJnsrO2bNmitLQ09e3bVzNmzNCOHTskMY9W0K0+LPCrr75Sa2trwA+DJKWkpOjTTz8NUlfdj9frlaSjzmPHOq/Xq+Tk5ID1DodDCQkJ/jFnm7a2Nt12220aOXKkBg8eLKl9nsLCwhQXFxcw9ttzebS57lh3ttiwYYM8Ho8aGxsVExOjhQsXKi8vT1VVVcxhJy1YsEAff/yx1qxZ8511/EyeuMLCQj333HPKzc1VTU2N7r//fl100UXauHEj82gB3SqgAMFUWlqqjRs36oMPPgh2K91Sbm6uqqqqVF9fr5dfflklJSWqqKgIdlvdzs6dO3XrrbdqyZIlioiICHY73drEiRP9XxcUFKiwsFBZWVn6y1/+osjIyCB2Bqmb3cWTmJiokJCQ71xFXVtbK7fbHaSuup+OuTrWPLrdbtXV1QWsb2lp0b59+87KuZ49e7YWLVqk9957T+np6f7lbrdbR44c0f79+wPGf3sujzbXHevOFmFhYerXr5+GDh2q8vJyDRkyRI8//jhz2Elr165VXV2dfvCDH8jhcMjhcKiiokK/+93v5HA4lJKSwnyepLi4OJ1zzjnaunUrP5cW0K0CSlhYmIYOHaqlS5f6l7W1tWnp0qXyeDxB7Kx7yc7OltvtDphHn8+nVatW+efR4/Fo//79Wrt2rX/MsmXL1NbWpsLCwjPec7AYYzR79mwtXLhQy5YtU3Z2dsD6oUOHKjQ0NGAuq6urtWPHjoC53LBhQ0DgW7JkiZxOp/Ly8s7ME7GgtrY2NTU1MYedNHbsWG3YsEFVVVX+GjZsmGbMmOH/mvk8OQcOHNC2bduUmprKz6UVBPsq3c5asGCBCQ8PN88995z55JNPzE033WTi4uICrqJG+xX+69atM+vWrTOSzKOPPmrWrVtnvvjiC2NM+23GcXFx5tVXXzXr168306ZNO+ptxuedd55ZtWqV+eCDD0z//v3PutuMZ82aZVwul1m+fHnArYiHDh3yj7n55ptNZmamWbZsmfnoo4+Mx+MxHo/Hv77jVsRx48aZqqoq89Zbb5mkpKSz6lbEu+++21RUVJjt27eb9evXm7vvvtvYbDbzzjvvGGOYw1P1zbt4jGE+T9Qdd9xhli9fbrZv327+9re/maKiIpOYmGjq6uqMMcxjsHW7gGKMMf/5n/9pMjMzTVhYmBk+fLj58MMPg92S5bz33ntG0neqpKTEGNN+q/G9995rUlJSTHh4uBk7dqyprq4O2MbevXvN1VdfbWJiYozT6TQ33HCDaWhoCMKzCZ6jzaEk8+yzz/rHHD582PzsZz8z8fHxJioqylx22WWmpqYmYDuff/65mThxoomMjDSJiYnmjjvuMM3NzWf42QTPv/zLv5isrCwTFhZmkpKSzNixY/3hxBjm8FR9O6Awnydm+vTpJjU11YSFhZnevXub6dOnm61bt/rXM4/BZTPGmOAcuwEAADi6bnUNCgAAODsQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOUQUAAAgOX8/2gS5f6nFHFHAAAAAElFTkSuQmCC\n"},"metadata":{}}],"source":["action_list = np.load(PATH, allow_pickle=True) # The action list you upload\n","seed = 543 # Do not revise this\n","\n","# åˆ›å»ºä¸€ä¸ªå¸¦æ¸²æŸ“åŠŸèƒ½çš„æµ‹è¯•ç¯å¢ƒ\n","test_env = gym.make('LunarLander-v3', render_mode='rgb_array')\n","fix(test_env, seed)\n","\n","agent.network.eval()  # set network to evaluation mode\n","\n","test_total_reward = []\n","if len(action_list) != 5:\n","    print(\"Wrong format of file !!!\")\n","    exit(0)\n","\n","for actions in action_list:\n","    state, _ = test_env.reset()\n","    img = plt.imshow(test_env.render())\n","\n","    total_reward = 0\n","    done = False\n","\n","    for action in actions:\n","\n","        state, reward, terminated, truncated, _ = test_env.step(action)\n","        done = terminated or truncated\n","        total_reward += reward\n","        if done:\n","            break\n","\n","    print(f\"Your reward is : %.2f\" % total_reward)\n","    test_total_reward.append(total_reward)"]},{"cell_type":"markdown","metadata":{"id":"TjFBWwQP1hVe"},"source":["# Your score"]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1757928373995,"user":{"displayName":"æ¹¯ç´","userId":"00701203190468333804"},"user_tz":-540},"id":"GpJpZz3Wbm0X","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8c56e7ab-8430-445e-878c-51fc53140af0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your final reward is : -262.44\n"]}],"source":["print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"]},{"cell_type":"markdown","metadata":{"id":"wUBtYXG2eaqf"},"source":["## Reference\n","\n","Below are some useful tips for you to get high score.\n","\n","- [DRL Lecture 1: Policy Gradient (Review)](https://youtu.be/z95ZYgPgXOY)\n","- [ML Lecture 23-3: Reinforcement Learning (including Q-learning) start at 30:00](https://youtu.be/2-JNBzCq77c?t=1800)\n","- [Lecture 7: Policy Gradient, David Silver](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/pg.pdf)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.11 (Lee Course)","language":"python","name":"lee_course_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"}},"nbformat":4,"nbformat_minor":0}